Feedback on the dissertation paper

- It nice overall but it rises a few questions like if we go with the increase false positive rate then why not focus on zero day ..?
- and how these varity of PPO & DQN and MLs how we gonna prove the proof of concept ..?
- also for the overall project we could foucs on latency as RL are heavy in real life(we are doing this in the environment) but we can foucs on latency rather than giving the best results on RL(As a AI you think about this a give me your opinion)
- what happened when the model  identifies the packet is vulnerable or benign? does it just drop..? and what happens that time, also in these time what can we display on the dashboard? like  stats we can stay this are the vulnerable packets and this are the benign packets and counts of them or a log kinda list in the dashboard? you can decide them and let me know the plan
- In Introduction you have mentioned about the the recent evidence on global average cost - you could kinda ignore/remove the costs number (as thats not relevant to our project)and just get the information from the last 4 year IBM report and see is there any change in stats in  data breach over last 4 years and also mentioned how many new types of attacks that has not detected by the traiditional IDS
- at first most of the RL agents are been trained on the traffic and they will understand what is good and bad on a repeated trainning why not on one of our scenarios we can have fully training RL agent (with different algorithms and MLs too)will be tested in the simulation and we will get the results and on scenarios 2 we can have a list of specific good traffic(a verified traffic) and give these list as a heads-up or parameters setup to the RL agents and MLs and see how they perform on that scenario(if the list of good traffic works then it means in real-life i could work as the company has a list of good traffic like remote user in difference domains and geography) by this we can say is of trail and error we can also have periodical updates on the good traffic list could improve the performance of the model than ML(as they need to be trained and tested) - so could update he sources needed to find evidence to see did any one did similar to this type of periodical update of good data list can boost the RL performance and also make sure you dont make it too conplex and stick with our project scope
- At the last part of the introduction, do you think we must have section 2,3,4,5 and explain that way or can we rephase it- just check yourself
- Mention what type of IDS we are planning to use or work with like is it anamoly or signature based or hybird.
- We can try heavy penalty if the RL model fails to reach the best results than ML
- In enhancing IDS with RL - Need evidence to that saying ML will fail to detect new types of attacks if not we cant just say it
- in improving the RL model accuracy or performance we can add the above points that i have mentioend with these existing points
- Update the dataset paragrah based on our recent changes in the codeside and keep the whole document upto sync
- for the challenges in real time- you see in the paper we have reference see is there any solution they have mentioned to fix this issue.
- If we are lost in the experiment to make the RL agent to the best performance we can try what's Microsoft & comparative studies concepts on our project (i do not mean the testing in reallife just follow the concepts or methoda how they managed to do it)
 - update the whole document base on the changes i have mentioned in this file and also keep all the information in the disseration paper upto sync. and for the idea on coding part you can think and take you time and decide what to do
 - based on these new changes if you need any new sources you know what to do, just update the sources_needed.md file and i can get you the sources you needed(also let me know this way of getting source or the soucre you are looking for is good or not) so i can improve myself.